{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main runner\n",
    "\n",
    "Notebook to help setup and run different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helpers import region_list\n",
    "import os\n",
    "import train_mlp_multi_species_model, train_mlp_single_species_model, train_transfer_learning, train_maml\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "hparams_root_dir = \"hparams\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi species MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with standard params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_path = os.path.join(\"logs\", \"logs_standard_params\")\n",
    "main_script = train_mlp_multi_species_model\n",
    "\n",
    "hparams_file = \"standard_multi_species.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "\n",
    "save_model_path = os.path.join(\"models\", \"models_standard_params\")\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--save_model_path\", save_model_path]\n",
    "    main_script.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with lower params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_lower_params\")\n",
    "main_script = train_mlp_multi_species_model\n",
    "\n",
    "hparams_file = \"lower_multi_species.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "save_model_path = os.path.join(\"models\", \"models_lower_params\")\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--save_model_path\", save_model_path]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with optuna params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using training data as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_train_val\")\n",
    "main_script = train_mlp_multi_species_model\n",
    "\n",
    "hparams_file = \"optuna_multi_species_using_train_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "save_model_path = os.path.join(\"models\", \"models_optuna_params_train_val\")\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--save_model_path\", save_model_path]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using test data as validation, non blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val\")\n",
    "main_script = train_mlp_multi_species_model\n",
    "\n",
    "hparams_file = \"optuna_multi_species_using_test_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "save_model_path = os.path.join(\"models\", \"models_optuna_params_test_val\")\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--save_model_path\", save_model_path]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using test data as validation, blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val_blocked_cv\")\n",
    "main_script = train_mlp_multi_species_model\n",
    "\n",
    "hparams_file = \"optuna_multi_species_using_test_val_blocked_cv.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "save_model_path = os.path.join(\"models\", \"models_optuna_params_test_val_blocked_cv\")\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--save_model_path\", save_model_path]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single species MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with standard params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_standard_params\")\n",
    "main_script = train_mlp_single_species_model\n",
    "\n",
    "hparams_file = \"standard_single_species.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with lower params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_lower_params\")\n",
    "main_script = train_mlp_single_species_model\n",
    "\n",
    "hparams_file = \"lower_single_species.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with optuna params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using training data as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_train_val\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_mlp_single_species_model\n",
    "\n",
    "hparams_file = \"optuna_single_species_using_train_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using test data as validation, non blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_mlp_single_species_model\n",
    "\n",
    "hparams_file = \"optuna_single_species_using_test_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using test data as validation, blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val_blocked_cv\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_mlp_single_species_model\n",
    "\n",
    "hparams_file = \"optuna_single_species_using_test_val_blocked_cv.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", f\"{log_path}\", \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From standard base parameter model, last layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_transfer_learning_last_layer_only_from_standard_base\")\n",
    "main_script = train_transfer_learning\n",
    "\n",
    "hparams_file = \"transfer_last_layer.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    load_model_path= os.path.join(\"models\", \"models_standard_params\", region, \"MULTI_SPECIES_MLP\", \"model.pt\")\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--load_model_path\", f\"{load_model_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From standard base parameter model, last layer only, but fine tuned for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_transfer_learning_last_layer_only_30epochs_from_standard_base\")\n",
    "main_script = train_transfer_learning\n",
    "\n",
    "hparams_file = \"transfer_last_layer_30epochs.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    load_model_path= os.path.join(\"models\", \"models_standard_params\", region, \"MULTI_SPECIES_MLP\", \"model.pt\")\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--load_model_path\", f\"{load_model_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From lower params, last layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_transfer_learning_last_layer_only_from_lower_params\")\n",
    "main_script = train_transfer_learning\n",
    "\n",
    "hparams_file = \"transfer_last_layer.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    load_model_path= os.path.join(\"models\", \"models_standard_params\", region, \"MULTI_SPECIES_MLP\", \"model.pt\")\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--load_model_path\", f\"{load_model_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From optuna params, last layer only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using training data as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_train_val\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_transfer_learning\n",
    "\n",
    "hparams_file = \"optuna_hparams_transfer_using_train_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    load_model_path= os.path.join(\"models\", \"models_optuna_params_train_val\", region, \"MULTI_SPECIES_MLP\", \"model.pt\")\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--load_model_path\", f\"{load_model_path}\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use test data as validation, non blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_transfer_learning\n",
    "\n",
    "hparams_file = \"optuna_hparams_transfer_using_test_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    load_model_path= os.path.join(\"models\", \"models_optuna_params_test_val\", region, \"MULTI_SPECIES_MLP\", \"model.pt\")\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--load_model_path\", f\"{load_model_path}\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use test data as validation, blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val_blocked_cv\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_transfer_learning\n",
    "\n",
    "hparams_file = \"optuna_hparams_transfer_using_test_val_blocked_cv.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "    load_model_path= os.path.join(\"models\", \"models_optuna_params_test_val_blocked_cv\", region, \"MULTI_SPECIES_MLP\", \"model.pt\")\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--load_model_path\", f\"{load_model_path}\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using training data as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_train_val\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_maml\n",
    "\n",
    "hparams_file = \"optuna_hparams_maml_using_train_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use test data as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda\n",
      "In region AWT, able to train on 40 out of 40 species, and 100.0% of data, which meet the requirement of having more than 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.27it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.41it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.49it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.17it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.51it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.54it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.45it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.52it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.41it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.48it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.47it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.61it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.55it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.45it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.51it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.55it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.21it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.44it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.52it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.58it/s]s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 46.82it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 45.82it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 40.62it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 45.08it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 46.33it/s]\n",
      " 43%|████▎     | 13/30 [00:00<00:00, 52.47it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 36.87it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 49.07it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 46.60it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 45.06it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 62.62it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 46.99it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 47.48it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 46.79it/s]\n",
      " 37%|███▋      | 11/30 [00:00<00:00, 51.39it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 48.71it/s]\n",
      " 33%|███▎      | 10/30 [00:00<00:00, 48.18it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 46.35it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 44.79it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 38.34it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 48.74it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 52.16it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 52.16it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 44.42it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 45.80it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 48.01it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 50.66it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 50.40it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 69.46it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 50.21it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 49.78it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 46.90it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 50.33it/s]\n",
      " 33%|███▎      | 10/30 [00:00<00:00, 53.58it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 47.04it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 49.80it/s]\n",
      " 40%|████      | 12/30 [00:00<00:00, 54.66it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 51.19it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 50.54it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda\n",
      "In region CAN, able to train on 20 out of 20 species, and 100.0% of data, which meet the requirement of having more than 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.53it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.07it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.55it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.40it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.53it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.44it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.58it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.31it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.54it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.63it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.40it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.29it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.57it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.55it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.81it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.64it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.50it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.47it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.36it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.50it/s]s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:02, 10.24it/s]\n",
      " 53%|█████▎    | 16/30 [00:01<00:01, 13.03it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:02, 10.09it/s]\n",
      " 20%|██        | 6/30 [00:00<00:02, 11.51it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:02, 10.56it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:02, 11.68it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:02, 10.73it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:02,  8.47it/s]\n",
      " 87%|████████▋ | 26/30 [00:02<00:00, 12.90it/s]\n",
      " 30%|███       | 9/30 [00:00<00:01, 12.69it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02,  9.00it/s]\n",
      " 30%|███       | 9/30 [00:00<00:01, 12.75it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:02, 10.82it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 12.62it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 11.39it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 10.55it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02,  9.48it/s]\n",
      " 63%|██████▎   | 19/30 [00:01<00:00, 12.71it/s]\n",
      " 30%|███       | 9/30 [00:00<00:01, 12.22it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda\n",
      "In region NSW, able to train on 53 out of 54 species, and 99.93981342160698% of data, which meet the requirement of having more than 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.97it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.44it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.12it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.20it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.21it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.36it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.58it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.38it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.46it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.44it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.11it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.41it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.17it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.31it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.97it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.22it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.42it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.34it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.34it/s]s]\n",
      "100%|██████████| 20/20 [00:12<00:00,  1.64it/s]\n",
      " 57%|█████▋    | 17/30 [00:00<00:00, 33.65it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 26.38it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 32.16it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 32.49it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 25.94it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 19.18it/s]\n",
      " 67%|██████▋   | 20/30 [00:00<00:00, 34.87it/s]\n",
      " 67%|██████▋   | 20/30 [00:00<00:00, 35.75it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 33.04it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 29.36it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 32.34it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:01, 20.45it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 30.93it/s]\n",
      " 30%|███       | 9/30 [00:00<00:00, 33.72it/s]\n",
      " 57%|█████▋    | 17/30 [00:00<00:00, 35.24it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 30.44it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 28.28it/s]\n",
      " 93%|█████████▎| 28/30 [00:01<00:00, 27.31it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 38.62it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 28.34it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 24.16it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:01, 18.67it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 25.86it/s]\n",
      " 43%|████▎     | 13/30 [00:00<00:00, 27.04it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:01, 17.19it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 26.73it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 27.85it/s]\n",
      " 93%|█████████▎| 28/30 [00:00<00:00, 31.77it/s]\n",
      " 43%|████▎     | 13/30 [00:00<00:00, 29.65it/s]\n",
      " 33%|███▎      | 10/30 [00:00<00:00, 24.57it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 26.51it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 23.87it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 29.49it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 17.62it/s]\n",
      " 70%|███████   | 21/30 [00:00<00:00, 33.03it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 24.99it/s]\n",
      " 40%|████      | 12/30 [00:00<00:00, 24.90it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 22.77it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 30.08it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 24.22it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 16.63it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 30.37it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 29.66it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 45.05it/s]\n",
      " 60%|██████    | 18/30 [00:00<00:00, 30.60it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 30.82it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 30.38it/s]\n",
      " 50%|█████     | 15/30 [00:00<00:00, 33.26it/s]\n",
      " 50%|█████     | 15/30 [00:00<00:00, 29.07it/s]\n",
      " 50%|█████     | 15/30 [00:00<00:00, 31.42it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 30.03it/s]\n",
      " 77%|███████▋  | 23/30 [00:00<00:00, 29.05it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 27.75it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 28.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda\n",
      "In region NZ, able to train on 52 out of 52 species, and 100.0% of data, which meet the requirement of having more than 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.44it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.77it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.48it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.24it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.46it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.15it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.44it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.16it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.33it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.12it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.29it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.22it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.30it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.42it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.12it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.13it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.22it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.21it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.28it/s]s]\n",
      "100%|██████████| 20/20 [00:12<00:00,  1.64it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  6.52it/s]\n",
      " 50%|█████     | 15/30 [00:01<00:01,  8.91it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  8.64it/s]\n",
      " 23%|██▎       | 7/30 [00:01<00:03,  6.73it/s]\n",
      " 60%|██████    | 18/30 [00:01<00:01,  9.20it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  8.32it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  8.74it/s]\n",
      " 53%|█████▎    | 16/30 [00:01<00:01,  9.05it/s]\n",
      " 63%|██████▎   | 19/30 [00:02<00:01,  9.30it/s]\n",
      " 20%|██        | 6/30 [00:00<00:03,  7.02it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  9.75it/s]\n",
      " 27%|██▋       | 8/30 [00:01<00:02,  7.38it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  8.38it/s]\n",
      " 60%|██████    | 18/30 [00:02<00:01,  7.58it/s]\n",
      " 53%|█████▎    | 16/30 [00:01<00:01,  8.66it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  8.40it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  9.89it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:04,  6.05it/s]\n",
      " 30%|███       | 9/30 [00:01<00:02,  8.57it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  9.38it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  9.25it/s]\n",
      " 40%|████      | 12/30 [00:01<00:02,  8.58it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  7.83it/s]\n",
      " 43%|████▎     | 13/30 [00:01<00:02,  8.08it/s]\n",
      " 57%|█████▋    | 17/30 [00:01<00:01,  9.30it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:02,  8.73it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  8.15it/s]\n",
      " 50%|█████     | 15/30 [00:01<00:01,  8.93it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  8.72it/s]\n",
      " 57%|█████▋    | 17/30 [00:01<00:01,  9.13it/s]\n",
      " 37%|███▋      | 11/30 [00:01<00:02,  8.44it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  7.59it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:04,  5.80it/s]\n",
      " 57%|█████▋    | 17/30 [00:02<00:01,  8.30it/s]\n",
      " 20%|██        | 6/30 [00:00<00:02,  8.94it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:03,  6.94it/s]\n",
      " 20%|██        | 6/30 [00:01<00:04,  5.96it/s]\n",
      " 57%|█████▋    | 17/30 [00:01<00:01,  8.87it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:02,  8.83it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:04,  6.49it/s]\n",
      " 20%|██        | 6/30 [00:00<00:03,  7.48it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02,  8.88it/s]\n",
      " 20%|██        | 6/30 [00:00<00:03,  7.43it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:02,  8.87it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:03,  7.10it/s]\n",
      " 40%|████      | 12/30 [00:01<00:01,  9.17it/s]\n",
      " 37%|███▋      | 11/30 [00:01<00:02,  8.31it/s]\n",
      " 43%|████▎     | 13/30 [00:01<00:01,  8.67it/s]\n",
      " 80%|████████  | 24/30 [00:02<00:00,  9.55it/s]\n",
      " 33%|███▎      | 10/30 [00:01<00:02,  8.46it/s]\n",
      " 47%|████▋     | 14/30 [00:01<00:01,  9.18it/s]\n",
      " 33%|███▎      | 10/30 [00:01<00:02,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda\n",
      "In region SA, able to train on 30 out of 30 species, and 100.0% of data, which meet the requirement of having more than 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.45it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.53it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.93it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.47it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.34it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.42it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.20it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.09it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.43it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.56it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.45it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.71it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.53it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.67it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.73it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.39it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.27it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.48it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.22it/s]s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 46.12it/s]\n",
      " 43%|████▎     | 13/30 [00:00<00:00, 49.64it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 48.18it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 52.90it/s]\n",
      " 30%|███       | 9/30 [00:00<00:00, 53.50it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 49.86it/s]\n",
      " 30%|███       | 9/30 [00:00<00:00, 54.50it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 48.55it/s]\n",
      " 23%|██▎       | 7/30 [00:00<00:00, 50.55it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 47.73it/s]\n",
      " 20%|██        | 6/30 [00:00<00:00, 48.69it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 49.19it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:00, 51.12it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 48.60it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 44.95it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 49.36it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 49.39it/s]\n",
      " 47%|████▋     | 14/30 [00:00<00:00, 47.64it/s]\n",
      " 30%|███       | 9/30 [00:00<00:00, 50.70it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 76.23it/s]\n",
      " 77%|███████▋  | 23/30 [00:00<00:00, 55.15it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 47.98it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 43.83it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 47.04it/s]\n",
      " 33%|███▎      | 10/30 [00:00<00:00, 50.60it/s]\n",
      " 50%|█████     | 15/30 [00:00<00:00, 51.40it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:00, 43.78it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 45.31it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 67.05it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:00, 45.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda\n",
      "In region SWI, able to train on 30 out of 30 species, and 100.0% of data, which meet the requirement of having more than 4 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.92it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  9.09it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.97it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.89it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.03it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.67it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.48it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.80it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.54it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.18it/s]]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.23it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.19it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.40it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.15it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.15it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.58it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.37it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.49it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.52it/s]s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.25it/s]s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.68it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:01, 14.32it/s]\n",
      " 47%|████▋     | 14/30 [00:01<00:01, 10.97it/s]\n",
      " 20%|██        | 6/30 [00:00<00:01, 13.51it/s]\n",
      " 97%|█████████▋| 29/30 [00:02<00:00, 14.36it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.99it/s]\n",
      " 33%|███▎      | 10/30 [00:00<00:01, 13.67it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.16it/s]\n",
      " 33%|███▎      | 10/30 [00:00<00:01, 14.78it/s]\n",
      " 57%|█████▋    | 17/30 [00:01<00:00, 13.19it/s]\n",
      " 87%|████████▋ | 26/30 [00:01<00:00, 14.81it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 13.71it/s]\n",
      " 43%|████▎     | 13/30 [00:01<00:01, 12.10it/s]\n",
      " 73%|███████▎  | 22/30 [00:01<00:00, 16.07it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:01, 11.32it/s]\n",
      " 57%|█████▋    | 17/30 [00:01<00:00, 15.64it/s]\n",
      " 20%|██        | 6/30 [00:00<00:02, 10.98it/s]\n",
      " 90%|█████████ | 27/30 [00:01<00:00, 15.43it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 10.81it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 13.26it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:01, 13.13it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.57it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 12.71it/s]\n",
      " 50%|█████     | 15/30 [00:01<00:01, 12.74it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 12.59it/s]\n",
      " 27%|██▋       | 8/30 [00:00<00:01, 12.65it/s]\n",
      " 57%|█████▋    | 17/30 [00:01<00:00, 14.75it/s]\n",
      " 17%|█▋        | 5/30 [00:00<00:01, 14.30it/s]\n",
      " 43%|████▎     | 13/30 [00:01<00:01, 12.96it/s]\n",
      " 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.48it/s]\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_maml\n",
    "\n",
    "hparams_file = \"optuna_hparams_maml_using_test_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use test data as validation, blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"logs\", \"logs_optuna_params_test_val_blocked_cv\")\n",
    "training_val_and_test_results_path = os.path.join(\"training_val_and_test_results\", log_path)\n",
    "main_script = train_maml\n",
    "\n",
    "hparams_file = \"optuna_hparams_maml_using_test_val_blocked_cv.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for region in region_list:\n",
    "\n",
    "    sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--training_val_and_test_results_path\", f\"{training_val_and_test_results_path}\"]\n",
    "    main_script.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing performance evolution on single species based on the number of samples it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_species = [\"awt06\", \"can02\", \"nsw09\", \"nz05\", \"sa26\", \"swi06\"]\n",
    "num_samples = [\"10\", \"50\", \"100\", \"200\"]\n",
    "main_script = train_maml\n",
    "\n",
    "hparams_file = \"optuna_hparams_maml_using_test_val.json\"\n",
    "hparams_path = os.path.join(hparams_root_dir, hparams_file)\n",
    "\n",
    "for num in num_samples:\n",
    "    for i, region in enumerate(region_list):\n",
    "\n",
    "        log_path = os.path.join(\"logs\", f\"logs_maml_evolution_{num}_samples\", specific_species[i])\n",
    "\n",
    "        sys.argv = [f\"{main_script.__name__}.py\", \"--hparams_path\", f\"{hparams_path}\", \"--log_path\", log_path, \"--region\", f\"{region}\", \"--scaler_path\", f\"Scalers/std_scaler_{region}.bin\", \"--specific_species\", specific_species[i], \"--num_samples\", num]\n",
    "        main_script.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm_meta_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
